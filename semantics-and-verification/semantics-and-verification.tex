\documentclass[toc]{../cs-classes/cs-classes}

\author{Xavier Rival and Jérôme Feret\\ Notes by Antoine Groudiev}
\title{Semantics and Applications to Verification}

\DeclareMathOperator{\lfp}{lfp}
\DeclareMathOperator{\gfp}{gfp}
\DeclareMathOperator{\pcl}{PCl}
\DeclareMathOperator{\Lim}{Lim}
\DeclareMathOperator{\safe}{Safe}
\DeclareMathOperator{\live}{Live}

\begin{document}
\section*{Introduction}
This document is Antoine Groudiev's class notes while following the class \emph{Sémantique et applications à la vérification de programmes} (Semantics and Applications to Verification) at the Computer Science Department of ENS Ulm. It is freely inspired by the class notes of Xavier Rival. 

\section{Introduction to Semantics}
\subsection{Case studies}
We will study some examples of software errors: what are the causes of these, what kind of properties do we want to verify in order to prevent such failures?
\subsubsection{Ariane 5 -- Flight 501}
Ariane 5 was a satellite launcher, aimed at replacing Ariane 4. Its first flight, June, 4th, 1996, was a failure, with more than \$370 000 000 of damages. 37 seconds after the launch, the rocket exploded. 

The system contained sensors, two calculators (SRI, OBC), actuators, and redundant systems (failure tolerant system). The failure was due to an unhandled arithmetic error. Each register of the  SRI has a size of 16, 32, or 64 bits. The error was due to a conversion of a 64-bit float to a 16-bit integer. The value was too large to be represented in 16 bits, and the conversion failed. The software was not able to handle this error, and the system crashed.

Several solutions would have prevented this mishappening:
\begin{itemize}
    \item Desactivate interruptions on overflows
    \item Fix the SRI code, so that no overflow can happen. All conversions must be \emph{guarded against overflows}:
    \begin{minted}{c}
                        double x = /* ... */ ;
                        short i = /* ... */ ;
                        if ( -32768. <= x && x <= 32767. )
                            i = ( short ) x ;
                        else
                            i = /* default value */ ;
    \end{minted}
    This may be costly, but redundant tests can be removed.
    \item Handle converson errors (not trivial): identify the problem and fix it at run time.
\end{itemize}

The piece of code that generated the error was used to do a useless task, the re-calibration process is not usefull after take-off. Furthermore, the code was already used in Ariane 4; initially protected by a safety guard, many conversions and tests were removed for the sake of performance after being tested on Ariane 4.

The crash was not prevented by redundant systems: the two calculators were running the same code, and the same error was made on both. Redundancy can prevent hardware errors, but is not enough to prevent software errors.

\subsubsection{Lufthansa Flight 2904}
On November 22, 2003, a Lufthansa Airbus A320-200 crashed at the airport of Warsaw, Poland. The plane was landing, and the weather was bad. The plane was not able to stop before the end of the runway, and crashed into a building. The cause of the crash was a software error in the plane's computer. The plane was not able to compute the correct deceleration, and the pilot was not able to stop the plane in time.

\subsubsection{Patriot missile (anti-missile system), Dahran}
The purporse of the Patriot system was to destroy foe missiles before they reach their target, and was used in the first Gulf War with a success rate around 50\%. The system was used to destroy Scud missiles, and the system was not able to destroy one of them, which hit a barrack, killing 28 people. The cause of the failure was a software error in the system's clock. The system was not able to compute the time correctly due to fixed precision arithmetic error, and the missile was not destroyed.

\subsubsection{General remarks}
The examples given so far are not isolated cases. The typical causes of software errors are:
\begin{itemize}
    \item Improper specification
    \item Incorrect implementation of a specification (the code should be free of runtime errors, and should produce a result that meets some property)
    \item Incorrect understanding of the execution model (generation of too imprecise results)
\end{itemize}

This creates new challenges to ensure embedded systems do not fail. The main techniques to ensure software safety are software development techniques:
\begin{itemize}
    \item software engineering
    \item programming rules
    \item make software cleaner
\end{itemize}

In this class, we will instead dive into formal methods:
\begin{itemize}
    \item should have sounds mathematical foundations
    \item should allow guaranteeing software meet some complex properties
    \item should be trustable
    \item increasingly used in real life applications
\end{itemize}

This course will contain two main parts. The first part will be about Semantics, which allow describing precisely the behavior of programs, express the properties to verify, and to transform and compile programs. The second part, Verification, aims at proving semantic properties of programs. A very strong limitation of verification is indecidability; several approaches make various compromises around indecidability.

\subsection{Approaches to verification}
\subsubsection{The termination problem}
\begin{definition}[Termination]
    A program $P$ terminates on input $X$ if and only if any execution of $P$ with input $X$ eventually reaches a final state. A final state is a final point in the program (i.e., not an error).
\end{definition}

\begin{definition}[Termination problem]
    Can we find a program $Pt$ that takes as argument a program $P$ and data $X$ and that returns \texttt{True} if $P$ terminates on $X$, and \texttt{False} otherwise?
\end{definition}

\begin{property}
    The termination problem is not computable.
\end{property}
\begin{proof}
    We assum there exists a program $Pa$ such that $Pa$ always terminates, and returns $1$ if and only if $P$ terminates on input $X$. We consider the following program:
    \begin{minted}{c}
void P0 ( P ) {
    if ( Pa ( P , P ) == 1 ) {
        while ( 1 ) {
            // loop forever
        }
    } else {
        return ; // do nothing
    }
}
    \end{minted}
    and we consider the return value of $Pa(P0, P0)$. If $Pa(P0, P0) == 1$, then $P0$ loops forever, and if $Pa(P0, P0) == 0$, then $P0$ terminates. This is a contradiction, and the termination problem is not computable.
\end{proof}

\begin{property}
    The absence of runtime errors is not computable. We cannot find a program $Pc$ that takes a program $P$ and input $X$ as arguments, always terminates, and returns $1$ if and only if $P$ runs on input $X$ without a runtime error.
\end{property}

\begin{theorem}[Rice theorem]
    Considering a Turing complete language, any non-trivial semantic specification is not computable. Therefore, all interesting properties are not computable (termination, absence of runtime/arithmetic errors, etc.).
\end{theorem}

The initial verification problem is not computable. Several compromises can be made: simulation, testing, assisted theorem proving, model checking, bug-finding, static analysis with abstraction.

\begin{definition}[Safety verification problem]
    The Semantics $\llbracket P\rrbracket$ of a program $P$ is the set of behaviors of $P$ (e.g. states). A property to verify $\S$ is the set of admissible behaviors (e.g. safe states). Our goal is to establish $\llbracket P\rrbracket \subseteq \S$
\end{definition}

$\llbracket P\rrbracket$ can be sound (identify any wrong program), complete (accept all correct programs), and automated, but not all three at the same time.

\paragraph*{Testing by simulation}
The principle of testing by simulation is to run the program on finitely many finite inputs, to maximize coverage and inspect erroneous traces to fix bugs. It is very widely used, through unit testing, integration testing, etc. It is both automated and complete, but is unsound and costly.

\paragraph*{Machine assisted proof}
The principle of machine assisted proof is to have a machine check proof that is partly human written: tactics or solvers may help in the inference, and the hardest invariants have to be user-supplied. It is sound and quasi-complete, but not fully automated and costly.

\paragraph*{Model checking}
We consider finite systems only, using algorithms for exhaustive exploration, symmetry reduction, \dots It is automated, sound, and complete \emph{with respect to the model}.

\paragraph*{Bug finding}
The principle of bug finding is to identify "likely" issues, patterns known to often indicate an error: it uses bounded symbolic execution, model exploration, and rank "defect" reports using heuristics. It is neither sound nor complete, but is fully automated.

\paragraph*{Static analysis with abstraction}
The principle of static analysis with abstraction is to use some approximation, but always in a conservative manner. We can use under-approximation of the property to verify:
\begin{equation*}
    \S_{\textnormal{under}}\subseteq\S
\end{equation*}
and over-approximation of the semantics:
\begin{equation*}
    \llbracket P\rrbracket\subseteq\llbracket P\rrbracket_{\textnormal{upper}}
\end{equation*}
We let an automatic static analyser attempt to prove that:
\begin{equation*}
    \llbracket P\rrbracket_{\textnormal{upper}}\subseteq\S_{\textnormal{under}}
\end{equation*}
If it succedds, then we have proven that $\llbracket P\rrbracket\subseteq\S$. It is automated, sound, but incomplete.

\subsubsection{A summary of common verification techniques}
\begin{figure}[!ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        &Automatic&Sound&Complete&Source level\\
        \hline
        \hline
        Simulation&Yes&No&Yes&Yes\\
        \hline
        Assisted Proving&No&Yes&Almost&Partially\\
        \hline
        Model-checking&Yes&Yes&Partially&No\\
        \hline
        Bug-finding&Yes&No&No&Yes\\
        \hline
        Static analysis&Yes&Yes&No&Yes\\
        \hline
    \end{tabular}
\end{figure}

\subsection{Orderings, lattices and fixpoints}
\subsubsection{Basic definitions on orderings}
\begin{definition}[Partially ordered set (poset)]
    Let a set $\S$ and a binary relation $(\sqsubseteq)\subseteq\S\times\S$ over $\S$. Then, $\sqsubseteq$ is an order relation if and only if it is reflexive, transitive, antisymettric. Furthermore, we define $x\sqsubset y::=(x\sqsubseteq y \land x\neq y)$. Most orders in this class won't be total.
\end{definition}

We often use Hasse diagrams to represent posets.

In the following, we illustrate order relations and their usefulness in semantics using the standard definition of \emph{word automata}. The semantics of an automaton is the set of words recognized by it.

We can already define a few semantic properties:
\begin{itemize}
    \item $\mathcal{P}_0$: no recognized word contains two consecutive $b$
    \begin{equation*}
        \L[\A]\subseteq L^\star\setminus L^\star bb L^\star
    \end{equation*}
    \item $\mathcal{P}_1$: all recognized words contain at least one occurrence of $a$
    \begin{equation*}
        \L[\A]\subseteq L^\star aL^\star
    \end{equation*}
    \item $\mathcal{P}_2$: recognized words do not contain $b$
    \begin{equation*}
        \L[\A]\subseteq (L\setminus \{b\})^\star
    \end{equation*}
\end{itemize}

\begin{definition}[$\bot$, $\top$]
    When they exist, we denote by infimum $\bot$ and supremum $\top$ the smallest and largest elements of the poset.
\end{definition}

\begin{definition}[$\sqcup$, $\sqcap$]
    We denote $\sqcap\S$ the glb (greatest lower bound) of $\S$, and $\sqcup$ the lub (lowest upper bound) of $\S$.
\end{definition}

\subsubsection{Complete lattice}
\begin{definition}[Complet lattice]
    A complete lattice is a tuple $(\S,\sqsubseteq,\bot,\top, \sqcup, \sqcap)$ where $(S, \sqsubseteq)$ is a poset, and any subset $\S'$ of $\S$ has a glb $\sqcap\S'$ and a lub $\sqcup\S$.
\end{definition}

\begin{definition}[Lattice]
    A lattice is a tuple $(\S,\sqsubseteq,\bot,\top, \sqcup, \sqcap)$ where $(S, \sqsubseteq)$, and any pair $\{x, y\}$ of $\S$ has a glb $x\sqcap y$ and a lub $x\sqcup y$.
\end{definition}
\begin{example}
    $\Q\cap[0, 1]$ is a lattice but not a complete lattice, since 
    \begin{equation*}
        \set{q\in \Q\cap[0, 1]}{q\leq\frac{\sqrt{2}}{2}}\subseteq\Q\cap[0, 1]
    \end{equation*} 
    has no lowest upper bound in $\Q\cap[0, 1]$.
\end{example}
\begin{property}
    A finite lattice is also a complete lattice.
\end{property}

\begin{definition}[Increasing chain]
    Let $(\S, \sqsubseteq)$ be a poset and $\mathcal{C}\subseteq \S$. It is an increasing chain if and only if it is not empty, and $(\mathcal{C}, \sqsubseteq)$ is total.
\end{definition}

\begin{example}
    In the powerset $(\mathcal{P}(\N), \subseteq)$, 
    \begin{equation*}
        \mathcal{C}:=\set{\{2^0, \dots, 2^i\}}{i\in\N}
    \end{equation*}
    is an increasing chain.
\end{example}

\begin{definition}[Increasing chain condition]
    The poset $(\S, \sqsubseteq)$ satisfies the increasing chain condition if and only if any increasing chain $\mathcal{C}\subseteq \S$ is finite.
\end{definition}

\begin{definition}[Complete partial order]
    A complete partial order (cpo) is a poset $(\S, \sqsubseteq)$ such that any increasing chain $\mathcal{C}$ of $\S$ has at least an upper bound. A pointed cpo is a cpo with a bottom element $\bot$.
\end{definition}

\subsubsection{How to prove semantic properties}

\subsubsection{Operators over a poset}
\begin{definition}[Operators and orderings]
    Let $(\S, \sqsubseteq)$ be a poset and $\phi:\S\to\S$ be an operator over $\S$. Then, $\phi$ is:
    \begin{itemize}
        \item \emph{monotone} if and only if $x\sqsubseteq y\Rightarrow \phi(x)\sqsubseteq\phi(y)$
        \item \emph{continuous} if and only if, for any \textbf{chain} $\S'\subseteq \S$, then:
        \begin{equation*}
            \begin{cases*}
                &if $\sqcup\S'$ exists, so does $\sqcup\phi(\S')$\\
                &and $\sqcup\phi(\S')=\phi(\sqcup\S')$
            \end{cases*}
        \end{equation*}
        \item $\sqcup$-preserving if and only if:
        \begin{equation*}
            \forall\S'\subseteq\S, \begin{cases*}
                &if $\sqcup\S'$ exists, so does $\sqcup\phi(\S')$\\
                &and $\sqcup\phi(\S')=\phi(\sqcup\S')$
            \end{cases*}
        \end{equation*}
    \end{itemize}
\end{definition}

\begin{property}[Continuity $\implies$ monotonicity]
    If $\phi$ is continuous, then it is monotone.
\end{property}

\begin{property}[$\sqcup$-preserving $\implies$ monotonicity]
    If $\phi$ preserves $\sqcup$, then it is monotone.
\end{property}

\subsubsection{Fixpoints theorems}
\begin{definition}[Fixpoints]
    Let $(\S, \sqsubseteq)$ be a poset and $\phi:\S\to\S$ be an operator over $\S$.
    \begin{itemize}
        \item A fixpoint of $\phi$ is an element $x$ such that $\phi(x)=x$.
        \item A pre-fixpoint of $\phi$ is an element $x$ such that $x\sqsubseteq\phi(x)$.
        \item A post-fixpoint of $\phi$ is an element $x$ such that $\phi(x)\sqsubseteq x$.
        \item The least fixpoint of $\phi$ is a fixpoint $x$ such that, for any fixpoint $y$, $x\sqsubseteq y$.
        \item The greatest fixpoint of $\phi$ is a fixpoint $x$ such that, for any fixpoint $y$, $y\sqsubseteq x$.
    \end{itemize}
\end{definition}

\begin{theorem}[Tarski's]
    Let $(\S, \sqsubseteq, \bot, \top, \sqcup, \sqcap)$ be a complete lattice and $\phi:\S\to\S$ be a monotone operator. Then:
    \begin{itemize}
        \item $\phi$ has a least fixpoint $\lfp\phi$ and $\lfp\phi = \sqcap\set{x\in\S}{\phi(x)\sqsubseteq x}$
        \item $\phi$ has a greatest fixpoint $\gfp\phi$ and $\gfp\phi = \sqcup\set{x\in\S}{x\sqsubseteq\phi(x)}$
        \item the set of fixpoints of $\phi$ is a complete lattice
    \end{itemize}
\end{theorem}

\begin{example}
    We consider a set $\mathcal{E}$, and a subset $\A\subseteq\mathcal{E}$. We let:
    \begin{equation*}
        \begin{aligned}
            f:\mathcal{P}(\mathcal{E}) &\to \mathcal{P}(\mathcal{E})\\
            X &\mapsto X\cup\A
        \end{aligned}
    \end{equation*}
    According to Tarski's theorem, the smallest fixpoint of $f$ is $\A$, and the greastest is $\mathcal{E}$.
\end{example}

\begin{theorem}[Kleene's]
    Let $(\S, \sqsubseteq, \bot)$ be a pointed cpo and $\phi:\S\to\S$ be a continuous operator over $\S$. The $\phi$ has a least fixpoint, and
    \begin{equation*}
        \lfp\phi = \bigsqcup_{n\in\N}\phi^n(\bot)
    \end{equation*}
\end{theorem}

\renewcommand{\S}{\mathbb{S}}
\newcommand{\B}{\mathbb{B}}

\section{Operational Semantics}
Operational semantics are mathematical descriptions of the executions of a program. It is based on a model of programs, called transition systems.

\subsection{Definition and properties}
\begin{definition}[Transition systems (TS)]
    A transition system is a tuple $(\S, \to)$ where $\S$ is the \emph{set of states of the system}, and $\to\subseteq\S\times\S$ is the transition relation of the system.
\end{definition}
Note that the set of states may be infinite. The majority of interesting examples come from the cases where $\S$ is infinite.

\begin{definition}[Deterministic system]
    A deterministic system is such that a state fully determines the next state.
    \begin{equation*}
        \forall s_0, s_1, s_1'\in\S, (s_0\to s_1 \land s_0\to s_1') \implies s_1 = s_1'
    \end{equation*}
    Otherwise, a transition system is non-deterministic.
\end{definition}

The transition relation $\to$ defines atomic execution steps. It is often called \emph{small-step semantics} or \emph{structured operational semantics}. Steps are \emph{discrete}, and we do not consider non-deterministic systems with probability on transitions (probabilistic transition systems).

\begin{definition}[Initial and final states]
    We often consider transition systems with a set of initial and final states:
    \begin{enumerate}
        \item a set of initial states $\S_I\subseteq\S$ denots states where the execution should start
        \item a set of final states $\S_F\subseteq\S$ denotes states where the execution should reach the end of the program
    \end{enumerate}
    When needed, we add these to the definition of the transition systems $(S, \to, \S_I, \S_F)$.
\end{definition}

\begin{definition}[Blocking state $\neq$ final state]
    A state $s_0\in\S$ is blocking when it is the origin of no transition:
    \begin{equation*}
        \forall s_1\in\S, \lnot(s_0\to s_1)
    \end{equation*}
    As an example, we often introduce an error state (usually noted $\Omega$)
\end{definition}

\subsection{Examples}
\subsubsection{Word recognition}
We can formalize the \emph{word recognition} by a finite automaton using a transition system. We consider an automaton $\A=(Q, q_i, q_f, \to)$. A state is defined by the remaining of the word to recognize, and the automaton state that has been reached so far. Thus,
\begin{equation*}
    \S = Q\times \Sigma^\star
\end{equation*}
We define the transition relation $\to$ to be:
\begin{equation*}
    (q_O, aw)\to(q_1, w) \iff q_0 \to^a q_1
\end{equation*}
The initial and final states are defined by:
\begin{equation*}
    \begin{cases*}
        \S_I = \set{(q_i, w)}{w\in\Sigma^\star} \\
        \S_F = \{(q_f, \epsilon)\}
    \end{cases*}
\end{equation*}

\subsubsection{Pure \texorpdfstring{$\lambda$}{ Ⲗ}-calculus}
A bare-bones model of functional programming:
\begin{definition}[$\lambda$-terms]
    The set of $\lambda$-terms is defined by:
        \begin{align*}
            t, u, \dots ::&= x & variable\\
            &| \lambda x\cdot t & abstraction\\
            &| tu & application
        \end{align*}
\end{definition}

\begin{definition}[$\beta$-reduction]
    % TODO
\end{definition}

The $\lambda$-calculus defines a transition system. $\S$ is the set of $\lambda$-terms and $\to_\beta$ the transition relation. $\to_\beta$ is non-deterministic, since multiple $\beta$-reduction are sometimes possible. Given a lambda term $t_0$, we may consider $(\S, \to_\beta, \S_I)$ where $\S_I = \{t_0\}$. Blocking states are terms with no redex $(\lambda x \cdot u)v$.

\subsection{A MIPS like assembly language}
We now consider a very simplified assembly language, containing machine integers $\B^{32}$. Instruction are encoded over 32 bits and stored in the same space as data, $\B^{32}$. We assume a fixed set of addresses $A$.

The memory configuration contains the program counter \texttt{pc}, the general purpose register $r_0, \dots, r_{31}$, and the main memory (RAM):
\begin{equation*}
    \mathbf{mem}:A\subseteq\B^{32}\to\B^{32}
\end{equation*}

\begin{definition}[State]
    A state is a tuple $(\pi, \rho, \mu)$ which comprises a program counter value $\pi\in\B^{32}$, a function mapping each general purpose register to its value $\rho : \{0, \dots, 32\} \to \B^{32}$, and a function mapping each memory cell to its value, $\mu:A\to\B^{32}$.
\end{definition}
We can define transition relations.

We now look at a more classical imperative language (a bare-bone subset of C), containing variables $X$, labels $L$, and values $V$. A syntax can be defined.

\subsection{Traces semantics}
\begin{definition}[Traces]
    A \emph{finite trace} is a finite sequence of states $s_0, \dots, s_n$ noted $\trace{s_0, \dots, s_n}$. An infinite trace is an infinite sequence of states $\trace{s_0, \dots}$. Besides, we write $\S^\star$ for the set of finite traces, $\S^\omega$ for the set of infinite traces, and $S^\alpha=\S^\star\cup\S^\omega$.
\end{definition}

\begin{definition}[Concatenation operator $\cdot$]
    
\end{definition}

\newcommand*{\Sc}{\mathcal{S}}
\section{Traces Properties}
\subsection{A high level overview}
The goal of verification is to prove that $\llbracket P \rrbracket\subseteq \Sc$ (i.e. that all behaviors of $P$ satisfy specifications $\Sc$) where $\llbracket P\rrbracket$ is the program semantics and $\Sc$ the desired specification. Today, we will mostly focus on program's properties, $\Sc$. We will see different families of properties, proof techniques, and specification of properties (are there languages to describe properties?).

A property is a set of traces, defining the admissible executions. There are \emph{safety properties}: something will never happen, which is often proven by invariance; \emph{liveness properties}: something will eventually happen, proven by variance; and beyond safety and liveness, there are \emph{hyperproperties}.

As usual, we consider $\Sc = (\S, \to, \S_{\mathcal{I}})$.
\begin{definition}[Properties as sets of states]
    A property $\mathcal{P}\subseteq\S$. $\mathcal{P}$ if all reacheable states belong to $\mathcal{P}$.
\end{definition}
This is the case of the absence of runtime errors, and non-termination.

\begin{definition}[Properties as sets of traces]
    A property $\mathcal{T}$ is a set of traces $\mathcal{T} \subseteq \S^\alpha$. $\mathcal{T}$ if and only if all traces belong to $\mathcal{T}$, i.e. $\llbracket\S\rrbracket^\alpha \subseteq \mathcal{T}$
\end{definition}
State properties are trace properties. Functional properties and termination are trace properties.

\begin{property}[Montonicity]
\end{property}

\subsection{Safety properties}
\subsubsection{Informal and formal definitions}
\begin{definition}[Informal definition of safety properties]
    A safety property is a property which specifies that some (bad) behavior defined by a finite, irrecoverable observation will never occur, at any time.
\end{definition}
\begin{example}
    The following properties are safety properties:
    \begin{itemize}
        \item Absence of runtime errors
        \item State properties
        \item Non-termination 
        \item \say{Not reaching state $b$ after visiting state $a$}
    \end{itemize}
    Termination is \textbf{not} a safety property, since no finite execution is a counter-example of its termination.
\end{example}

We now intend to provide a formal definition of safety. How to refute a safety property? We assume $\Sc$ does not satisfy safety property $\mathcal{P}$. Thus, there exists a counter-example trace $\sigma=\trace{s_0, \dots, s_n, \dots}\in \llbracket S \rrbracket \setminus \mathcal{P}$. At this point of our study, the trace may be finite or infinite. ... A safety property that does not hold can always be refuted with a finite, irrecoverable counter-example.

\paragraph*{A few operators on traces}
\begin{definition}[Prefix]
    We write $\sigma_{\lceil i}$ for the prefix of length $i$ of trace $\sigma$.
\end{definition}

\begin{definition}[Suffix or tail]
    We write $\sigma_{i \rceil}$ for the suffix of length $i$ of trace $\sigma$.
\end{definition}

\begin{definition}[Upper closure operators]
    In a preorder $(\Sc, \sqsubseteq)$, a function $\phi : \Sc \to \Sc$ is an upper closure operatof if and only if it is monotone, extensive ($\forall x\in \Sc, x\sqsubseteq \phi(x)$) and idempotent.
\end{definition}

\begin{definition}[Prefix closure]
    The prefix closure operatof is defined by:
    \begin{equation*}
        \begin{aligned}
            \pcl : \mathcal{P}(\S^\alpha) &\to \mathcal{P}(\S^\star)\\
            X &\mapsto \set{\sigma_{\lceil i}}{\sigma\in X, i\in \N}
        \end{aligned}
    \end{equation*}
    $\pcl$ is monotone, idempotent, but not extensive on $\mathcal{P}(\S^\alpha)$ (infinite traces do not appear anymore). Its restriction to $\mathcal{P}(\S^\star)$ is extensive.
\end{definition}

\begin{definition}[The $\Lim$ operator]
    The limit operator is defined by:
    \begin{equation*}
    \begin{aligned}
        \Lim : \mathcal{P}(\S^\alpha) &\to \mathcal{P}(\S^\alpha)\\
        X &\mapsto X\cup \set{\sigma\in\S^\alpha}{\forall i\in\N, \sigma_{\lceil i}\in X}
    \end{aligned}
    \end{equation*}
    Note that the operator $\Lim$ is an upper-closure operator.
\end{definition}
\begin{proof}
    Left as an exercise!
\end{proof}

\begin{example}
    Assume that:
    \begin{equation*}
        \Sc = \{\epsilon, \trace{a}, \trace{a, b}, \trace{a, b, a}, \trace{a, b, a, b}, \trace{a, b, a, b, a}, \dots \}
    \end{equation*}
    then, 
    \begin{equation*}
        \Lim(\Sc) = \Sc \cup \{\trace{a, b, a, b, a, b, \dots}\}
    \end{equation*}
\end{example}

\begin{definition}[The $\safe$ operator]
    Operator $\safe$ is defined by
    \begin{equation*}
        \safe = \Lim\circ\pcl
    \end{equation*}
    Note that $\safe$ is an upper closure operator over $\mathcal{P}(\S^\alpha)$.
\end{definition}

\begin{definition}[Safety property]
    A trace property $\mathcal{T}$ is a safety property if and only if it is a fixpoint of the $\safe$ operator, that is
    \begin{equation*}
        \safe(\mathcal{T}) = \mathcal{T}
    \end{equation*}
    Furthermore, if $\mathcal{T}$ is a trace property, then $\safe(\mathcal{T})$ is a safety property, since $\safe$ is idempotent.
\end{definition}

\begin{theorem}
    Any state property is also a safety property.
\end{theorem}

\subsubsection{Proof method}

\subsection{Liveness properties}
\subsubsection{Informal and formal definitions}

\subsubsection{Proof method}

\subsection{Decomposition of trace properties}
\begin{theorem}
    Let $\mathcal{T}\subseteq \S^\alpha$; it can be decomposed into the conjunction of safety property $\safe(\mathcal{T})$ and liveness property $\live(\mathcal{T})$:
    \begin{equation*}
        \mathcal{T} = \safe(\mathcal{T}) \cap \live(\mathcal{T})
    \end{equation*}
\end{theorem}

\subsection{A specification language: temporal logic}

\subsection{Beyond safety and liveness}

\end{document}